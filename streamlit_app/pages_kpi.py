# streamlit_app/pages_kpi.py

import streamlit as st

def page_kpi():
    st.title("Notes & KPI")


    st.markdown(
        """
        # Notes & KPI ‚Äî Traitement des donn√©es & Machine Learning

## 1. Sources de donn√©es

### Donn√©es IMDB (brutes)

* `name.basics.tsv.gz`
* `title.basics.tsv.gz`
* `title.crew.tsv.gz`
* `title.principals.tsv.gz`
* `title.ratings.tsv.gz`

Ces fichiers constituent la base brute IMDB. Ils **ne sont jamais utilis√©s directement** dans Streamlit.

### Donn√©es externes

* INSEE : d√©mographie, m√©nages, pauvret√©, salaires
* CNC : √©crans, entr√©es, fr√©quentation cin√©ma
* TMDB (API) : posters, titres FR, synopsis, popularit√©

---

## 2. Nettoyage et pr√©paration des donn√©es (offline)

### Objectif

Construire un **catalogue films propre, l√©ger et exploitable** pour la recommandation et l‚Äôaffichage.

### √âtapes principales

1. **Filtrage des films**

   * Suppression des contenus non-films (s√©ries, √©pisodes)
   * Filtrage temporel (films r√©cents / pertinents)
   * Seuils de votes pour garantir une base fiable

2. **Nettoyage des champs**

   * Harmonisation des genres
   * Suppression des valeurs manquantes critiques
   * Normalisation des titres et identifiants

3. **Construction des fichiers finaux**

   * `movies_local.csv.gz`

     * Identifiant IMDb (`tconst`)
     * Titre principal
     * Ann√©e de sortie
     * Genres
     * Donn√©es utiles √† l‚Äôaffichage

   * `movies_features.csv.gz`

     * Identifiant IMDb
     * Texte descriptif ("soup") pour le ML

üëâ Ces √©tapes sont r√©alis√©es via des **scripts Python offline** (`scripts/`), jamais sur Streamlit Cloud.

---

## 3. Feature Engineering pour la recommandation

### Principe de la "soup"

Chaque film est repr√©sent√© par un texte combinant :

* Genres
* R√©alisateur
* Acteurs principaux

Exemple (simplifi√©) :

```
Drama Thriller nolan dicaprio hardy
```

Ce format permet une vectorisation simple et efficace.

---

## 4. Mod√®le de recommandation

### 4.1 Logique g√©n√©rale du Machine Learning

Le syst√®me de recommandation repose sur un **mod√®le de type Content-Based Filtering**. Le principe est de repr√©senter chaque film sous forme vectorielle, √† partir de ses caract√©ristiques textuelles, puis de mesurer la similarit√© entre films.

L‚Äôint√©gralit√© de la phase d‚Äôapprentissage est r√©alis√©e **en amont (offline)** afin de garantir de bonnes performances dans l‚Äôapplication Streamlit.

---

### 4.2 Pr√©paration des donn√©es pour le ML (en amont)

√Ä partir de la base nettoy√©e issue d‚ÄôIMDB, une table d√©di√©e au Machine Learning est construite (`movies_features.csv.gz`).

Pour chaque film, on g√©n√®re une **repr√©sentation textuelle unique appel√©e "soup"**, qui agr√®ge :

* les genres du film
* le r√©alisateur principal
* les acteurs principaux

Exemple de soup :

```
Drama Thriller nolan dicaprio hardy
```

Cette √©tape est cruciale : elle permet de transformer des donn√©es h√©t√©rog√®nes (cat√©gories, noms propres) en une forme exploitable par un mod√®le NLP simple.

---

### 4.3 Vectorisation TF-IDF (fit offline)

Une fois la colonne "soup" construite pour l‚Äôensemble du catalogue :

1. Un **TF-IDF Vectorizer** est entra√Æn√© sur l‚Äôint√©gralit√© des soups du catalogue
2. Chaque film est transform√© en un **vecteur num√©rique** de dimension √©lev√©e

Ce processus produit :

* une matrice creuse TF-IDF (films √ó termes)
* un vocabulaire pond√©r√© par l‚Äôimportance des mots

Les fichiers g√©n√©r√©s sont :

* `tfidf_vectorizer.joblib` ‚Üí le mod√®le TF-IDF entra√Æn√© (fit)
* `tfidf_matrix.joblib` ‚Üí la matrice vectoris√©e des films
* `tconst_index.csv` ‚Üí mapping entre identifiant IMDb et index de ligne

Ces artefacts sont sauvegard√©s sur disque et **ne sont jamais recalcul√©s dans Streamlit**.

---

### 4.4 Chargement et utilisation dans Streamlit

Dans l‚Äôapplication :

* les artefacts sont charg√©s une seule fois via `st.cache_resource`
* la matrice et le vectorizer restent en m√©moire pour toutes les sessions

Deux cas d‚Äôusage sont alors possibles.

---

### 4.5 Recommandation √† partir d‚Äôun film du catalogue

Lorsque l‚Äôutilisateur s√©lectionne un film d√©j√† pr√©sent dans la base locale :

1. On r√©cup√®re son index dans la matrice TF-IDF
2. On calcule la **similarit√© cosinus** entre son vecteur et tous les autres films
3. On trie les scores et on retourne les films les plus similaires

Ce m√©canisme est rapide car il s‚Äôappuie uniquement sur des calculs matriciels en m√©moire.

---

### 4.6 Recommandation √† partir d‚Äôun film externe (API TMDB)

Pour un film **absent du catalogue local** (par exemple issu de la recherche TMDB) :

1. Les informations du film sont r√©cup√©r√©es via l‚ÄôAPI TMDB
2. Une soup est construite dynamiquement (genres + r√©alisateur + acteurs)
3. Cette soup est **transform√©e** avec le vectorizer existant (pas de refit)
4. Le vecteur obtenu est compar√© √† la matrice TF-IDF locale via similarit√© cosinus

üëâ Le mod√®le n‚Äôest jamais r√©entra√Æn√© : on applique uniquement une **transformation** coh√©rente avec l‚Äôapprentissage initial.

---

### 4.7 Coh√©rence entre donn√©es locales et donn√©es API

Le point cl√© du syst√®me est la **coh√©rence du pipeline** :

* m√™me logique de soup
* m√™me normalisation (minuscules, espaces)
* m√™me vectorizer

Cela garantit que les films issus de l‚ÄôAPI TMDB sont projet√©s dans **le m√™me espace vectoriel** que les films du catalogue local.

---

### 4.8 Pourquoi ce choix de mod√®le

Ce mod√®le a √©t√© choisi car il :

* est explicable
* ne n√©cessite pas de donn√©es utilisateurs
* est rapide et robuste
* est parfaitement adapt√© √† un contexte Data Analyst

Il permet de d√©montrer une cha√Æne ML compl√®te sans complexit√© inutile.

---

### 4.9 Limites sp√©cifiques du ML

* Pas de prise en compte des pr√©f√©rences utilisateurs
* Sensible √† la qualit√© des m√©tadonn√©es (genres, casting)
* Ne capture pas les relations s√©mantiques profondes

---

### 4.10 √âvolutions possibles

* Passage √† des embeddings (Word2Vec, SBERT)
* Ajout d‚Äôun scoring hybride (contenu + popularit√©)
* Int√©gration de feedback utilisateur

### Type de mod√®le

* **Content-Based Filtering**
* Aucun apprentissage supervis√©
* Pas de donn√©es utilisateur

### M√©thode

1. Vectorisation TF-IDF sur la soup
2. Calcul de similarit√© cosinus entre films
3. Classement des films les plus proches

### Artefacts produits

* `tfidf_vectorizer.joblib`
* `tfidf_matrix.joblib`
* `tconst_index.csv`

Ces fichiers sont charg√©s **une seule fois** dans Streamlit gr√¢ce √† `st.cache_resource`.

---

## 5. Int√©gration TMDB (enrichissement)

### R√¥le de TMDB

* Titres en fran√ßais
* Posters et backdrops
* Synopsis
* Popularit√©

### Fonctionnement

* Appels API encapsul√©s dans `tmdb_client.py`
* Cache disque + cache Streamlit
* Aucun enrichissement massif au chargement

### Principe cl√©

üëâ **L‚Äôenrichissement se fait uniquement √† l‚Äôaffichage** (Top 5 / cartes visibles)

Cela garantit :

* Performance
* Respect des quotas API

---

## 6. Reranking et contextualisation

Pour certains cas (films √† l‚Äôaffiche / √† venir) :

* Construction de sets IMDb `now_playing` / `upcoming`
* Permet d‚Äôannoter ou prioriser les recommandations

Ces calculs sont :

* Mis en cache
* Recalcul√©s √† intervalle contr√¥l√© (TTL)

---

## 7. Architecture Streamlit (r√©sum√©)

* **Offline** : nettoyage, feature engineering, ML
* **Online (Streamlit)** :

  * Chargement des fichiers finaux
  * Recommandation en temps r√©el
  * Enrichissement visuel √† la demande

Cette s√©paration garantit :

* Performance
* Reproductibilit√©
* Scalabilit√©

---

## 8. Limites identifi√©es

* Pas de personnalisation utilisateur
* Recommandation bas√©e uniquement sur le contenu
* D√©pendance partielle √† une API externe (TMDB)

---

## Conclusion

Le projet met en ≈ìuvre une **cha√Æne compl√®te de data analysis appliqu√©e** :

* collecte
* nettoyage
* feature engineering
* machine learning
* d√©ploiement applicatif

Le tout dans une architecture **adapt√©e √† un contexte Data Analyst**, claire, performante et justifiable.


        """
    )
    st.markdown(
        """
        # üìä KPI ‚Äì Traitement des donn√©es

        """        
    )
    


    

import pandas as pd

def page_kpi():
    st.title("Notes & KPI")

    # ============================
    # INTRO
    # ============================
    st.markdown(
        "Bienvenue dans le Hub. Voici les **KPI cl√©s** du territoire, du cin√©ma et du moteur de recommandation**."
    )

    # ============================
    # 1) KPI INSEE
    # ============================

    st.subheader("üìä D√©mographie ‚Äî INSEE")

    col1, col2, col3 = st.columns(3)
    col1.metric("Population totale", "118 000")
    col2.metric("60 ans et +", "47 %", "+6 pts depuis 2011")
    col3.metric("Moins de 30 ans", "22 %", "-4 pts depuis 2011")

    col4, col5 = st.columns(2)
    col4.metric("M√©nages d'une personne", "41 %")
    col5.metric("Pauvret√© <30 ans", "25 %")

    st.markdown("---")

    # ============================
    # 2) KPI CNC
    # ============================

    st.subheader("üé¨ Cin√©ma ‚Äî CNC")

    col1, col2, col3 = st.columns(3)
    col1.metric("√âcrans (2024)", "4", "-67 % depuis 1966")
    col2.metric("Entr√©es annuelles", "45 000", "Stable")
    col3.metric("Entr√©es / habitant", "0.35", "France : 2.8")

    col4, col5 = st.columns(2)
    col4.metric("S√©ances annuelles", "2 000")
    col5.metric("Taux d'occupation", "0.25", "-50 % vs France")

    st.markdown("---")

    # ============================
    # 3) KPI AVANT TRAITEMENT IMDB
    # ============================

    st.header("üì¶ Bases de donn√©es ")

    col1, col2, col3 = st.columns(3)
    col1.metric("Films TMDB (brut)", "309 572")
    col2.metric("Fichiers IMDB bruts", "5 fichiers")
    col3.metric("Colonnes TMDB", "40")

    

    st.markdown("---")

    # ============================
    # 4) KPI APR√àS TRAITEMENT IMDB (sans df)
    # ============================

    

    col1, col2, col3 = st.columns(3)
    col1.metric("Films IMDB (apr√®s traitement)", "38 924" )
    col2.metric( "TMDB final", "1 Fichiers")
    col3.metric("Colonnes finales", "9")

   
    

    st.markdown("---")

    # ============================
    # 5) KPI TRAITEMENT IMDB (avec df)
    # ============================

   
    @st.cache_data
    def load_features():
        return pd.read_csv("data/data_processed/movies_local.csv.gz")

    df = load_features()

    processing_kpi = {
        "films_total": len(df),
        "genres_valides": df["genres"].notna().mean() * 100,
        "directors_valides": df["director_names"].notna().mean() * 100,
        "casting_valide": df["cast_names_top5"].notna().mean() * 100,
        "runtime_valide": df["runtimeMinutes"].gt(0).mean() * 100,
        "soup_completude": 100.0,
        "longueur_moyenne_soup": 55,
        "vocabulaire_tfidf": "40k‚Äì60k tokens",
    }

   

    st.markdown("---")

    # ============================
    # 6) KPI RECOMMANDATION
    # ============================

    st.header("ü§ñ Moteur de recommandation (contenu)")

    reco_kpi = {
        "films_recommandables": len(df),
        "diversite_genres": df["genres"].str.split(",").explode().nunique(),
        "richesse_cast": df["cast_names_top5"].str.split("|").explode().nunique(),
        "temps_reco": "< 50 ms",
        
    }

    col1, col2, col3 = st.columns(3)
    col1.metric("Films recommandables", f"{reco_kpi['films_recommandables']:,}")
    col2.metric("Genres uniques", f"{reco_kpi['diversite_genres']}")
    col3.metric("Acteurs uniques", f"{reco_kpi['richesse_cast']:,}")

    st.metric("Vocabulaire TF‚ÄëIDF", processing_kpi["vocabulaire_tfidf"])
    col3.metric("Longueur moyenne soup", f"{processing_kpi['longueur_moyenne_soup']} mots")
    

    st.markdown("---")

    # ============================
    # 7) APER√áU DATASET
    # ============================

    st.subheader("Aper√ßu du dataset IMDB")
    st.dataframe(df.head())
